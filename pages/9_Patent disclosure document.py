import streamlit as st
import anthropic
import ollama as ol
import streamlit as st
from streamlit_mic_recorder import speech_to_text
import datetime
import json

def log_interaction(action, data):
    timestamp = datetime.datetime.now().isoformat()
    log = {"timestamp": timestamp, "action": action, "data": data}
    with open("user_interactions_log.json", "a") as logfile:
        logfile.write(json.dumps(log) + "\n")

def print_txt(text):
    if any("\u0600" <= c <= "\u06FF" for c in text):  # check if text contains Arabic characters
        text = f"<p style='direction: rtl; text-align: right;'>{text}</p>"
    st.markdown(text, unsafe_allow_html=True)

def print_chat_message(message):
    text = message["content"]
    if message["role"] == "user":
        with st.chat_message("user", avatar="ğŸ™ï¸"):
            print_txt(text)
    elif message["role"] == "assistant":
        with st.chat_message("assistant", avatar="ğŸ¦™"):
            print_txt(text)

def get_chat_history(key):
    return st.session_state.chat_history[key]

def init_chat_history(key, system_prompt):
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = {}
    if key not in st.session_state.chat_history:
        st.session_state.chat_history[key] = [{"role": "system", "content": system_prompt}]

def system_prompt_input(default_prompt):
    return st.sidebar.text_area("System Prompt", value=default_prompt, height=100)

def llm_selector():
    ollama_models = [m['name'] for m in ol.list()['models']]
    with st.sidebar:
        return st.selectbox("LLM", ollama_models)


# è®¾ç½®é¡µé¢æ ‡é¢˜å’Œå›¾æ ‡
st.set_page_config(page_title="ä¸“åˆ©äº¤åº•ä¹¦", page_icon="ğŸ“")

st.title("ğŸ“ ä¸“åˆ©äº¤åº•ä¹¦")

uploaded_file = st.file_uploader("Upload an article", type=("txt", "md", "docx"))

model = llm_selector()
chat_key = f"å¯¹è¯_chat_history_{model}"  # Unique key for each mode and model
default_prompt = (
    "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ä¸­æ–‡åŠ©æ‰‹ï¼Œè¯·è¯¦ç»†å›ç­”æˆ‘çš„ä»»ä½•é—®é¢˜ï¼Œå¹¶ä¸”ç”¨ä¸­æ–‡å›ç­”æˆ‘ã€‚"
    "æˆ‘éœ€è¦æ’°å†™ä¸€ç¯‡ä¸“åˆ©äº¤åº•ä¹¦ï¼Œè¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¯¦ç»†å›ç­”ï¼š"
    "å‘æ˜åç§°ã€"
    "æŠ€æœ¯é¢†åŸŸã€"
    "ç°æœ‰æŠ€æœ¯çš„æŠ€æœ¯æ–¹æ¡ˆã€"
    "ç°æœ‰æŠ€æœ¯çš„ç¼ºé™·ã€"
    "ä¸æœ¬å‘æ˜ç›¸å…³çš„ç°æœ‰æŠ€æœ¯äºŒã€"
    "æœ¬å‘æ˜æ‰€è¦è§£å†³çš„æŠ€æœ¯é—®é¢˜ã€"
    "æœ¬å‘æ˜æä¾›çš„å®Œæ•´æŠ€æœ¯æ–¹æ¡ˆã€"
    "æœ¬å‘æ˜çš„å®æ–½ä¾‹ã€"
    "æœ¬å‘æ˜æŠ€æœ¯æ–¹æ¡ˆå–å¾—çš„æŠ€æœ¯è¿›æ­¥ã€"
    "æœ¬å‘æ˜æŠ€æœ¯æ–¹æ¡ˆå¸¦æ¥çš„æœ‰ç›Šæ•ˆæœã€"
    "æœ¬å‘æ˜æŠ€æœ¯æ–¹æ¡ˆå¸¦æ¥æœ‰ç›Šæ•ˆæœçš„åŸå› ã€"
    "æ˜¯å¦è¿˜æœ‰å…¶ä»–æ›¿ä»£æ–¹æ¡ˆåŒæ ·èƒ½å®Œæˆå‘æ˜ç›®çš„ã€"
    "æœ¬å‘æ˜çš„æŠ€æœ¯å…³é”®ç‚¹å’Œæ¬²ä¿æŠ¤ç‚¹æ˜¯ä»€ä¹ˆã€‚"
    "è¯·é€ä¸€å›ç­”ä»¥ä¸Šæ‰€æœ‰é—®é¢˜ï¼Œç¡®ä¿å†…å®¹è¯¦å°½ã€æ¸…æ™°ï¼Œå¹¶ç¬¦åˆä¸“åˆ©äº¤åº•ä¹¦çš„æ’°å†™è¦æ±‚ã€‚"
)

system_prompt = system_prompt_input(default_prompt)
init_chat_history(chat_key, system_prompt)
chat_history = get_chat_history(chat_key)
for message in chat_history:
    print_chat_message(message)

question = st.chat_input()

debug_mode = st.sidebar.checkbox("Debug Mode", value=True)
log_interaction("User input", {"mode": "å¯¹è¯", "question": question})

if question:
    prompt = f"""{anthropic.HUMAN_PROMPT} Here's an article:\n\n<article>
    {question}\n\n</article>\n\n{question}{anthropic.AI_PROMPT}"""

    if question:
        user_message = {"role": "user", "content": question}

        print_chat_message(user_message)
        chat_history.append(user_message)

        if uploaded_file:
            article = uploaded_file.read().decode()
            chat_history.append({"role": "user", "content": article})  # æ·»åŠ ç”¨æˆ·ä¸Šä¼ çš„æ–‡ä»¶å†…å®¹ä½œä¸ºå¯¹è¯å†å²çš„ä¸€éƒ¨åˆ†

        response = ol.chat(model=model, messages=chat_history)
        answer = response["message"]["content"]
        ai_message = {"role": "assistant", "content": answer}
        print_chat_message(ai_message)
        chat_history.append(ai_message)
        debug_info = {"messages": chat_history, "response": response}

        if debug_mode:
            st.write("Debug Info: Complete Prompt Interaction")
            st.json(debug_info)

        # Truncate chat history to keep 20 messages max
        if len(chat_history) > 20:
            chat_history = chat_history[-20:]

        # Update chat history
        st.session_state.chat_history[chat_key] = chat_history
