
import streamlit as st
import anthropic
import ollama as ol
import streamlit as st
from streamlit_mic_recorder import speech_to_text
import datetime
import json

def log_interaction(action, data):
    timestamp = datetime.datetime.now().isoformat()
    log = {"timestamp": timestamp, "action": action, "data": data}
    with open("user_interactions_log.json", "a") as logfile:
        logfile.write(json.dumps(log) + "\n")

def print_txt(text):
    if any("\u0600" <= c <= "\u06FF" for c in text):  # check if text contains Arabic characters
        text = f"<p style='direction: rtl; text-align: right;'>{text}</p>"
    st.markdown(text, unsafe_allow_html=True)

def print_chat_message(message):
    text = message["content"]
    if message["role"] == "user":
        with st.chat_message("user", avatar="ðŸŽ™ï¸"):
            print_txt(text)
    elif message["role"] == "assistant":
        with st.chat_message("assistant", avatar="ðŸ¦™"):
            print_txt(text)

def get_chat_history(key):
    return st.session_state.chat_history[key]

def init_chat_history(key, system_prompt):
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = {}
    if key not in st.session_state.chat_history:
        st.session_state.chat_history[key] = [{"role": "system", "content": system_prompt}]

def system_prompt_input(default_prompt):
    return st.sidebar.text_area("System Prompt", value=default_prompt, height=100)

def llm_selector():
    ollama_models = [m['name'] for m in ol.list()['models']]
    with st.sidebar:
        return st.selectbox("LLM", ollama_models)




# è®¾ç½®é¡µé¢æ ‡é¢˜å’Œå›¾æ ‡
st.set_page_config(page_title="å›¾åƒå¤„ç†", page_icon="ðŸ–¼ï¸")

st.title("ðŸ–¼ï¸ å›¾åƒå¤„ç†")
uploaded_file = st.file_uploader("ä¸Šä¼ å›¾åƒ", type=("png"))

model = llm_selector()
chat_key = f"å¯¹è¯_chat_history_{model}"  # Unique key for each mode and model
default_prompt = ("æˆ‘çŽ°åœ¨å°†è¦ç»™ä½ ä¼ é€ä¸€å¼ å›¾ç‰‡ï¼Œä½ éœ€è¦è¯†åˆ«å›¾åƒä¸­çš„æ–‡å­—ç„¶åŽç»™æˆ‘å‘é€å¤„ç†åŽçš„æ–‡æœ¬ï¼ˆå…³é”®è¯ã€çŸ­è¯­ç­‰ï¼‰ã€‚")

system_prompt = system_prompt_input(default_prompt)
init_chat_history(chat_key, system_prompt)
chat_history = get_chat_history(chat_key)

debug_mode = st.sidebar.checkbox("Debug Mode", value=True)

# åˆ›å»ºä¸¤åˆ—å¸ƒå±€ï¼Œå·¦è¾¹æ˜¾ç¤ºç”¨æˆ·è¾“å…¥ï¼Œå³è¾¹æ˜¾ç¤ºæ¨¡åž‹è¾“å‡º
user_input_col, model_output_col = st.columns(2)

# ç”¨æˆ·è¾“å…¥åˆ—
with user_input_col:
    question = st.text_area("ç”¨æˆ·è¾“å…¥")
    if st.button("æäº¤"):
        log_interaction("User input", {"mode": "å¯¹è¯", "question": question})

        if question:
            user_message = {"role": "user", "content": question}
            print_chat_message(user_message)
            chat_history.append(user_message)

            if uploaded_file:
                article = uploaded_file.read().decode('utf-8', 'ignore')
                chat_history.append({"role": "user", "content": article})

            response = ol.chat(model=model, messages=chat_history)
            answer = response['message']['content']

            # æ¨¡åž‹è¾“å‡ºåˆ—
            with model_output_col:
                ai_message = {"role": "assistant", "content": answer}
                print_chat_message(ai_message)
                chat_history.append(ai_message)

                debug_info = {"messages": chat_history, "response": response}

                if debug_mode:
                    st.write("Debug Info: Complete Prompt Interaction")
                    st.json(debug_info)

                if len(chat_history) > 20:
                    chat_history = chat_history[-20:]


                st.session_state.chat_history[chat_key] = chat_history
